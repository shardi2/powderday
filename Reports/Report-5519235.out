---------------------------------------
Begin Slurm Prolog: Apr-03-2024 15:28:21
Job ID:    5519235
User ID:   shardin31
Account:   gts-jw254-coda20
Job name:  Slurmshardinpowderdayrun
Partition: cpu-small
QOS:       inferno
---------------------------------------

CommandNotFoundError: Your shell has not been properly configured to use 'conda deactivate'.
To initialize your shell, run

    $ conda init <SHELL_NAME>

Currently supported shells are:
  - bash
  - fish
  - tcsh
  - xonsh
  - zsh
  - powershell

See 'conda init --help' for more information and options.

IMPORTANT: You may need to close and restart your shell after running 'conda init'.



Lmod is automatically replacing "mvapich2/2.3.6-ouywal" with "openmpi/4.1.4".

yt : [INFO     ] 2024-04-03 15:28:45,990 Global parallel computation enabled: 23 / 48
yt : [INFO     ] 2024-04-03 15:28:45,990 Global parallel computation enabled: 29 / 48
yt : [INFO     ] 2024-04-03 15:28:45,991 Global parallel computation enabled: 5 / 48
yt : [INFO     ] 2024-04-03 15:28:45,991 Global parallel computation enabled: 1 / 48
yt : [INFO     ] 2024-04-03 15:28:45,992 Global parallel computation enabled: 3 / 48
yt : [INFO     ] 2024-04-03 15:28:45,992 Global parallel computation enabled: 13 / 48
yt : [INFO     ] 2024-04-03 15:28:45,992 Global parallel computation enabled: 15 / 48
yt : [INFO     ] 2024-04-03 15:28:45,993 Global parallel computation enabled: 12 / 48
yt : [INFO     ] 2024-04-03 15:28:45,993 Global parallel computation enabled: 16 / 48
yt : [INFO     ] 2024-04-03 15:28:45,993 Global parallel computation enabled: 10 / 48
yt : [INFO     ] 2024-04-03 15:28:45,994 Global parallel computation enabled: 0 / 48
yt : [INFO     ] 2024-04-03 15:28:45,995 Global parallel computation enabled: 11 / 48
yt : [INFO     ] 2024-04-03 15:28:45,995 Global parallel computation enabled: 9 / 48
yt : [INFO     ] 2024-04-03 15:28:45,996 Global parallel computation enabled: 17 / 48
yt : [INFO     ] 2024-04-03 15:28:45,996 Global parallel computation enabled: 8 / 48
yt : [INFO     ] 2024-04-03 15:28:45,996 Global parallel computation enabled: 4 / 48
yt : [INFO     ] 2024-04-03 15:28:45,997 Global parallel computation enabled: 19 / 48
yt : [INFO     ] 2024-04-03 15:28:45,997 Global parallel computation enabled: 6 / 48
yt : [INFO     ] 2024-04-03 15:28:45,997 Global parallel computation enabled: 20 / 48
yt : [INFO     ] 2024-04-03 15:28:45,998 Global parallel computation enabled: 18 / 48
yt : [INFO     ] 2024-04-03 15:28:46,005 Global parallel computation enabled: 2 / 48
yt : [INFO     ] 2024-04-03 15:28:46,009 Global parallel computation enabled: 21 / 48
yt : [INFO     ] 2024-04-03 15:28:46,009 Global parallel computation enabled: 22 / 48
yt : [INFO     ] 2024-04-03 15:28:46,012 Global parallel computation enabled: 14 / 48
yt : [INFO     ] 2024-04-03 15:28:46,014 Global parallel computation enabled: 7 / 48
yt : [INFO     ] 2024-04-03 15:28:45,991 Global parallel computation enabled: 33 / 48
yt : [INFO     ] 2024-04-03 15:28:45,992 Global parallel computation enabled: 41 / 48
yt : [INFO     ] 2024-04-03 15:28:45,993 Global parallel computation enabled: 28 / 48
yt : [INFO     ] 2024-04-03 15:28:45,993 Global parallel computation enabled: 37 / 48
yt : [INFO     ] 2024-04-03 15:28:45,994 Global parallel computation enabled: 42 / 48
yt : [INFO     ] 2024-04-03 15:28:45,994 Global parallel computation enabled: 43 / 48
yt : [INFO     ] 2024-04-03 15:28:45,994 Global parallel computation enabled: 26 / 48
yt : [INFO     ] 2024-04-03 15:28:45,994 Global parallel computation enabled: 38 / 48
yt : [INFO     ] 2024-04-03 15:28:45,995 Global parallel computation enabled: 46 / 48
yt : [INFO     ] 2024-04-03 15:28:45,995 Global parallel computation enabled: 45 / 48
yt : [INFO     ] 2024-04-03 15:28:45,995 Global parallel computation enabled: 27 / 48
yt : [INFO     ] 2024-04-03 15:28:45,995 Global parallel computation enabled: 40 / 48
yt : [INFO     ] 2024-04-03 15:28:45,996 Global parallel computation enabled: 34 / 48
yt : [INFO     ] 2024-04-03 15:28:45,996 Global parallel computation enabled: 31 / 48
yt : [INFO     ] 2024-04-03 15:28:45,996 Global parallel computation enabled: 47 / 48
yt : [INFO     ] 2024-04-03 15:28:45,997 Global parallel computation enabled: 32 / 48
yt : [INFO     ] 2024-04-03 15:28:45,997 Global parallel computation enabled: 24 / 48
yt : [INFO     ] 2024-04-03 15:28:45,998 Global parallel computation enabled: 39 / 48
yt : [INFO     ] 2024-04-03 15:28:46,005 Global parallel computation enabled: 35 / 48
yt : [INFO     ] 2024-04-03 15:28:46,006 Global parallel computation enabled: 36 / 48
yt : [INFO     ] 2024-04-03 15:28:46,010 Global parallel computation enabled: 25 / 48
yt : [INFO     ] 2024-04-03 15:28:46,010 Global parallel computation enabled: 30 / 48
yt : [INFO     ] 2024-04-03 15:28:46,010 Global parallel computation enabled: 44 / 48
Additional features and improved performance (usually) by saving this arbor with "save_arbor" and reloading:
	>>> a = ytree.load("/storage/home/hcoda1/0/jw254/data/SG64-2020/rockstar_halos-jhw/trees/tree_0_0_0.dat")
	>>> fn = a.save_arbor()
	>>> a = ytree.load(fn)
Additional features and improved performance (usually) by saving this arbor with "save_arbor" and reloading:
	>>> a = ytree.load("/storage/home/hcoda1/0/jw254/data/SG64-2020/rockstar_halos-jhw/trees/tree_0_0_0.dat")
	>>> fn = a.save_arbor()
	>>> a = ytree.load(fn)
Additional features and improved performance (usually) by saving this arbor with "save_arbor" and reloading:
	>>> a = ytree.load("/storage/home/hcoda1/0/jw254/data/SG64-2020/rockstar_halos-jhw/trees/tree_0_0_0.dat")
	>>> fn = a.save_arbor()
	>>> a = ytree.load(fn)
Additional features and improved performance (usually) by saving this arbor with "save_arbor" and reloading:
	>>> a = ytree.load("/storage/home/hcoda1/0/jw254/data/SG64-2020/rockstar_halos-jhw/trees/tree_0_0_0.dat")
	>>> fn = a.save_arbor()
	>>> a = ytree.load(fn)
Additional features and improved performance (usually) by saving this arbor with "save_arbor" and reloading:
	>>> a = ytree.load("/storage/home/hcoda1/0/jw254/data/SG64-2020/rockstar_halos-jhw/trees/tree_0_0_0.dat")
	>>> fn = a.save_arbor()
	>>> a = ytree.load(fn)
Additional features and improved performance (usually) by saving this arbor with "save_arbor" and reloading:
	>>> a = ytree.load("/storage/home/hcoda1/0/jw254/data/SG64-2020/rockstar_halos-jhw/trees/tree_0_0_0.dat")
	>>> fn = a.save_arbor()
	>>> a = ytree.load(fn)
Additional features and improved performance (usually) by saving this arbor with "save_arbor" and reloading:
	>>> a = ytree.load("/storage/home/hcoda1/0/jw254/data/SG64-2020/rockstar_halos-jhw/trees/tree_0_0_0.dat")
	>>> fn = a.save_arbor()
	>>> a = ytree.load(fn)
Additional features and improved performance (usually) by saving this arbor with "save_arbor" and reloading:
	>>> a = ytree.load("/storage/home/hcoda1/0/jw254/data/SG64-2020/rockstar_halos-jhw/trees/tree_0_0_0.dat")
	>>> fn = a.save_arbor()
	>>> a = ytree.load(fn)
Additional features and improved performance (usually) by saving this arbor with "save_arbor" and reloading:
	>>> a = ytree.load("/storage/home/hcoda1/0/jw254/data/SG64-2020/rockstar_halos-jhw/trees/tree_0_0_0.dat")
	>>> fn = a.save_arbor()
	>>> a = ytree.load(fn)
Additional features and improved performance (usually) by saving this arbor with "save_arbor" and reloading:
	>>> a = ytree.load("/storage/home/hcoda1/0/jw254/data/SG64-2020/rockstar_halos-jhw/trees/tree_0_0_0.dat")
	>>> fn = a.save_arbor()
	>>> a = ytree.load(fn)
Additional features and improved performance (usually) by saving this arbor with "save_arbor" and reloading:
	>>> a = ytree.load("/storage/home/hcoda1/0/jw254/data/SG64-2020/rockstar_halos-jhw/trees/tree_0_0_0.dat")
	>>> fn = a.save_arbor()
	>>> a = ytree.load(fn)
Additional features and improved performance (usually) by saving this arbor with "save_arbor" and reloading:
	>>> a = ytree.load("/storage/home/hcoda1/0/jw254/data/SG64-2020/rockstar_halos-jhw/trees/tree_0_0_0.dat")
	>>> fn = a.save_arbor()
	>>> a = ytree.load(fn)
Additional features and improved performance (usually) by saving this arbor with "save_arbor" and reloading:
	>>> a = ytree.load("/storage/home/hcoda1/0/jw254/data/SG64-2020/rockstar_halos-jhw/trees/tree_0_0_0.dat")
	>>> fn = a.save_arbor()
	>>> a = ytree.load(fn)
Additional features and improved performance (usually) by saving this arbor with "save_arbor" and reloading:
	>>> a = ytree.load("/storage/home/hcoda1/0/jw254/data/SG64-2020/rockstar_halos-jhw/trees/tree_0_0_0.dat")
	>>> fn = a.save_arbor()
	>>> a = ytree.load(fn)
Additional features and improved performance (usually) by saving this arbor with "save_arbor" and reloading:
	>>> a = ytree.load("/storage/home/hcoda1/0/jw254/data/SG64-2020/rockstar_halos-jhw/trees/tree_0_0_0.dat")
	>>> fn = a.save_arbor()
	>>> a = ytree.load(fn)
Additional features and improved performance (usually) by saving this arbor with "save_arbor" and reloading:
	>>> a = ytree.load("/storage/home/hcoda1/0/jw254/data/SG64-2020/rockstar_halos-jhw/trees/tree_0_0_0.dat")
	>>> fn = a.save_arbor()
	>>> a = ytree.load(fn)
Additional features and improved performance (usually) by saving this arbor with "save_arbor" and reloading:
	>>> a = ytree.load("/storage/home/hcoda1/0/jw254/data/SG64-2020/rockstar_halos-jhw/trees/tree_0_0_0.dat")
	>>> fn = a.save_arbor()
	>>> a = ytree.load(fn)
Additional features and improved performance (usually) by saving this arbor with "save_arbor" and reloading:
	>>> a = ytree.load("/storage/home/hcoda1/0/jw254/data/SG64-2020/rockstar_halos-jhw/trees/tree_0_0_0.dat")
	>>> fn = a.save_arbor()
	>>> a = ytree.load(fn)
Additional features and improved performance (usually) by saving this arbor with "save_arbor" and reloading:
	>>> a = ytree.load("/storage/home/hcoda1/0/jw254/data/SG64-2020/rockstar_halos-jhw/trees/tree_0_0_0.dat")
	>>> fn = a.save_arbor()
	>>> a = ytree.load(fn)
Additional features and improved performance (usually) by saving this arbor with "save_arbor" and reloading:
	>>> a = ytree.load("/storage/home/hcoda1/0/jw254/data/SG64-2020/rockstar_halos-jhw/trees/tree_0_0_0.dat")
	>>> fn = a.save_arbor()
	>>> a = ytree.load(fn)
Additional features and improved performance (usually) by saving this arbor with "save_arbor" and reloading:
	>>> a = ytree.load("/storage/home/hcoda1/0/jw254/data/SG64-2020/rockstar_halos-jhw/trees/tree_0_0_0.dat")
	>>> fn = a.save_arbor()
	>>> a = ytree.load(fn)
Additional features and improved performance (usually) by saving this arbor with "save_arbor" and reloading:
	>>> a = ytree.load("/storage/home/hcoda1/0/jw254/data/SG64-2020/rockstar_halos-jhw/trees/tree_0_0_0.dat")
	>>> fn = a.save_arbor()
	>>> a = ytree.load(fn)
Additional features and improved performance (usually) by saving this arbor with "save_arbor" and reloading:
	>>> a = ytree.load("/storage/home/hcoda1/0/jw254/data/SG64-2020/rockstar_halos-jhw/trees/tree_0_0_0.dat")
	>>> fn = a.save_arbor()
	>>> a = ytree.load(fn)
Additional features and improved performance (usually) by saving this arbor with "save_arbor" and reloading:
	>>> a = ytree.load("/storage/home/hcoda1/0/jw254/data/SG64-2020/rockstar_halos-jhw/trees/tree_0_0_0.dat")
	>>> fn = a.save_arbor()
	>>> a = ytree.load(fn)
Additional features and improved performance (usually) by saving this arbor with "save_arbor" and reloading:
	>>> a = ytree.load("/storage/home/hcoda1/0/jw254/data/SG64-2020/rockstar_halos-jhw/trees/tree_0_0_0.dat")
	>>> fn = a.save_arbor()
	>>> a = ytree.load(fn)
Additional features and improved performance (usually) by saving this arbor with "save_arbor" and reloading:
	>>> a = ytree.load("/storage/home/hcoda1/0/jw254/data/SG64-2020/rockstar_halos-jhw/trees/tree_0_0_0.dat")
	>>> fn = a.save_arbor()
	>>> a = ytree.load(fn)
Additional features and improved performance (usually) by saving this arbor with "save_arbor" and reloading:
	>>> a = ytree.load("/storage/home/hcoda1/0/jw254/data/SG64-2020/rockstar_halos-jhw/trees/tree_0_0_0.dat")
	>>> fn = a.save_arbor()
	>>> a = ytree.load(fn)
Additional features and improved performance (usually) by saving this arbor with "save_arbor" and reloading:
	>>> a = ytree.load("/storage/home/hcoda1/0/jw254/data/SG64-2020/rockstar_halos-jhw/trees/tree_0_0_0.dat")
	>>> fn = a.save_arbor()
	>>> a = ytree.load(fn)
Additional features and improved performance (usually) by saving this arbor with "save_arbor" and reloading:
	>>> a = ytree.load("/storage/home/hcoda1/0/jw254/data/SG64-2020/rockstar_halos-jhw/trees/tree_0_0_0.dat")
	>>> fn = a.save_arbor()
	>>> a = ytree.load(fn)
Additional features and improved performance (usually) by saving this arbor with "save_arbor" and reloading:
	>>> a = ytree.load("/storage/home/hcoda1/0/jw254/data/SG64-2020/rockstar_halos-jhw/trees/tree_0_0_0.dat")
	>>> fn = a.save_arbor()
	>>> a = ytree.load(fn)
Additional features and improved performance (usually) by saving this arbor with "save_arbor" and reloading:
	>>> a = ytree.load("/storage/home/hcoda1/0/jw254/data/SG64-2020/rockstar_halos-jhw/trees/tree_0_0_0.dat")
	>>> fn = a.save_arbor()
	>>> a = ytree.load(fn)
Additional features and improved performance (usually) by saving this arbor with "save_arbor" and reloading:
	>>> a = ytree.load("/storage/home/hcoda1/0/jw254/data/SG64-2020/rockstar_halos-jhw/trees/tree_0_0_0.dat")
	>>> fn = a.save_arbor()
	>>> a = ytree.load(fn)
Additional features and improved performance (usually) by saving this arbor with "save_arbor" and reloading:
	>>> a = ytree.load("/storage/home/hcoda1/0/jw254/data/SG64-2020/rockstar_halos-jhw/trees/tree_0_0_0.dat")
	>>> fn = a.save_arbor()
	>>> a = ytree.load(fn)
Additional features and improved performance (usually) by saving this arbor with "save_arbor" and reloading:
	>>> a = ytree.load("/storage/home/hcoda1/0/jw254/data/SG64-2020/rockstar_halos-jhw/trees/tree_0_0_0.dat")
	>>> fn = a.save_arbor()
	>>> a = ytree.load(fn)
Additional features and improved performance (usually) by saving this arbor with "save_arbor" and reloading:
	>>> a = ytree.load("/storage/home/hcoda1/0/jw254/data/SG64-2020/rockstar_halos-jhw/trees/tree_0_0_0.dat")
	>>> fn = a.save_arbor()
	>>> a = ytree.load(fn)
Additional features and improved performance (usually) by saving this arbor with "save_arbor" and reloading:
	>>> a = ytree.load("/storage/home/hcoda1/0/jw254/data/SG64-2020/rockstar_halos-jhw/trees/tree_0_0_0.dat")
	>>> fn = a.save_arbor()
	>>> a = ytree.load(fn)
Additional features and improved performance (usually) by saving this arbor with "save_arbor" and reloading:
	>>> a = ytree.load("/storage/home/hcoda1/0/jw254/data/SG64-2020/rockstar_halos-jhw/trees/tree_0_0_0.dat")
	>>> fn = a.save_arbor()
	>>> a = ytree.load(fn)
Additional features and improved performance (usually) by saving this arbor with "save_arbor" and reloading:
	>>> a = ytree.load("/storage/home/hcoda1/0/jw254/data/SG64-2020/rockstar_halos-jhw/trees/tree_0_0_0.dat")
	>>> fn = a.save_arbor()
	>>> a = ytree.load(fn)
Additional features and improved performance (usually) by saving this arbor with "save_arbor" and reloading:
	>>> a = ytree.load("/storage/home/hcoda1/0/jw254/data/SG64-2020/rockstar_halos-jhw/trees/tree_0_0_0.dat")
	>>> fn = a.save_arbor()
	>>> a = ytree.load(fn)
Additional features and improved performance (usually) by saving this arbor with "save_arbor" and reloading:
	>>> a = ytree.load("/storage/home/hcoda1/0/jw254/data/SG64-2020/rockstar_halos-jhw/trees/tree_0_0_0.dat")
	>>> fn = a.save_arbor()
	>>> a = ytree.load(fn)
  File "stellar_mass.py", line 92, in <module>
    ap.add_recipe(stellar_mass_recipe)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_pipeline.py", line 140, in add_recipe
    recipe(self)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_operators.py", line 30, in __call__
    return self.function(target, *self.args, **self.kwargs)
P027 yt : [ERROR    ] 2024-04-03 15:28:46,076 TypeError: stellar_mass_recipe() missing 1 required positional argument: 'outputs'
  File "stellar_mass.py", line 92, in <module>
    ap.add_recipe(stellar_mass_recipe)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_pipeline.py", line 140, in add_recipe
    recipe(self)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_operators.py", line 30, in __call__
    return self.function(target, *self.args, **self.kwargs)
P004 yt : [ERROR    ] 2024-04-03 15:28:46,076 TypeError: stellar_mass_recipe() missing 1 required positional argument: 'outputs'
  File "stellar_mass.py", line 92, in <module>
    ap.add_recipe(stellar_mass_recipe)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_pipeline.py", line 140, in add_recipe
    recipe(self)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_operators.py", line 30, in __call__
    return self.function(target, *self.args, **self.kwargs)
P005 yt : [ERROR    ] 2024-04-03 15:28:46,076 TypeError: stellar_mass_recipe() missing 1 required positional argument: 'outputs'
  File "stellar_mass.py", line 92, in <module>
    ap.add_recipe(stellar_mass_recipe)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_pipeline.py", line 140, in add_recipe
    recipe(self)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_operators.py", line 30, in __call__
    return self.function(target, *self.args, **self.kwargs)
P013 yt : [ERROR    ] 2024-04-03 15:28:46,076 TypeError: stellar_mass_recipe() missing 1 required positional argument: 'outputs'
  File "stellar_mass.py", line 92, in <module>
    ap.add_recipe(stellar_mass_recipe)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_pipeline.py", line 140, in add_recipe
    recipe(self)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_operators.py", line 30, in __call__
    return self.function(target, *self.args, **self.kwargs)
P034 yt : [ERROR    ] 2024-04-03 15:28:46,076 TypeError: stellar_mass_recipe() missing 1 required positional argument: 'outputs'
  File "stellar_mass.py", line 92, in <module>
    ap.add_recipe(stellar_mass_recipe)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_pipeline.py", line 140, in add_recipe
    recipe(self)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_operators.py", line 30, in __call__
    return self.function(target, *self.args, **self.kwargs)
P016 yt : [ERROR    ] 2024-04-03 15:28:46,076 TypeError: stellar_mass_recipe() missing 1 required positional argument: 'outputs'
  File "stellar_mass.py", line 92, in <module>
    ap.add_recipe(stellar_mass_recipe)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_pipeline.py", line 140, in add_recipe
    recipe(self)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_operators.py", line 30, in __call__
    return self.function(target, *self.args, **self.kwargs)
P043 yt : [ERROR    ] 2024-04-03 15:28:46,076 TypeError: stellar_mass_recipe() missing 1 required positional argument: 'outputs'
  File "stellar_mass.py", line 92, in <module>
    ap.add_recipe(stellar_mass_recipe)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_pipeline.py", line 140, in add_recipe
    recipe(self)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_operators.py", line 30, in __call__
    return self.function(target, *self.args, **self.kwargs)
P000 yt : [ERROR    ] 2024-04-03 15:28:46,076 TypeError: stellar_mass_recipe() missing 1 required positional argument: 'outputs'
  File "stellar_mass.py", line 92, in <module>
    ap.add_recipe(stellar_mass_recipe)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_pipeline.py", line 140, in add_recipe
    recipe(self)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_operators.py", line 30, in __call__
    return self.function(target, *self.args, **self.kwargs)
P024 yt : [ERROR    ] 2024-04-03 15:28:46,076 TypeError: stellar_mass_recipe() missing 1 required positional argument: 'outputs'
  File "stellar_mass.py", line 92, in <module>
    ap.add_recipe(stellar_mass_recipe)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_pipeline.py", line 140, in add_recipe
    recipe(self)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_operators.py", line 30, in __call__
    return self.function(target, *self.args, **self.kwargs)
P003 yt : [ERROR    ] 2024-04-03 15:28:46,076 TypeError: stellar_mass_recipe() missing 1 required positional argument: 'outputs'
  File "stellar_mass.py", line 92, in <module>
    ap.add_recipe(stellar_mass_recipe)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_pipeline.py", line 140, in add_recipe
    recipe(self)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_operators.py", line 30, in __call__
    return self.function(target, *self.args, **self.kwargs)
P026 yt : [ERROR    ] 2024-04-03 15:28:46,076 TypeError: stellar_mass_recipe() missing 1 required positional argument: 'outputs'
  File "stellar_mass.py", line 92, in <module>
    ap.add_recipe(stellar_mass_recipe)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_pipeline.py", line 140, in add_recipe
    recipe(self)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_operators.py", line 30, in __call__
    return self.function(target, *self.args, **self.kwargs)
P006 yt : [ERROR    ] 2024-04-03 15:28:46,076 TypeError: stellar_mass_recipe() missing 1 required positional argument: 'outputs'
  File "stellar_mass.py", line 92, in <module>
    ap.add_recipe(stellar_mass_recipe)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_pipeline.py", line 140, in add_recipe
    recipe(self)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_operators.py", line 30, in __call__
    return self.function(target, *self.args, **self.kwargs)
P029 yt : [ERROR    ] 2024-04-03 15:28:46,076 TypeError: stellar_mass_recipe() missing 1 required positional argument: 'outputs'
  File "stellar_mass.py", line 92, in <module>
    ap.add_recipe(stellar_mass_recipe)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_pipeline.py", line 140, in add_recipe
    recipe(self)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_operators.py", line 30, in __call__
    return self.function(target, *self.args, **self.kwargs)
P009 yt : [ERROR    ] 2024-04-03 15:28:46,076 TypeError: stellar_mass_recipe() missing 1 required positional argument: 'outputs'
  File "stellar_mass.py", line 92, in <module>
    ap.add_recipe(stellar_mass_recipe)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_pipeline.py", line 140, in add_recipe
    recipe(self)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_operators.py", line 30, in __call__
    return self.function(target, *self.args, **self.kwargs)
P031 yt : [ERROR    ] 2024-04-03 15:28:46,076 TypeError: stellar_mass_recipe() missing 1 required positional argument: 'outputs'
  File "stellar_mass.py", line 92, in <module>
    ap.add_recipe(stellar_mass_recipe)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_pipeline.py", line 140, in add_recipe
    recipe(self)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_operators.py", line 30, in __call__
    return self.function(target, *self.args, **self.kwargs)
P010 yt : [ERROR    ] 2024-04-03 15:28:46,076 TypeError: stellar_mass_recipe() missing 1 required positional argument: 'outputs'
  File "stellar_mass.py", line 92, in <module>
    ap.add_recipe(stellar_mass_recipe)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_pipeline.py", line 140, in add_recipe
    recipe(self)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_operators.py", line 30, in __call__
    return self.function(target, *self.args, **self.kwargs)
P032 yt : [ERROR    ] 2024-04-03 15:28:46,076 TypeError: stellar_mass_recipe() missing 1 required positional argument: 'outputs'
  File "stellar_mass.py", line 92, in <module>
    ap.add_recipe(stellar_mass_recipe)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_pipeline.py", line 140, in add_recipe
    recipe(self)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_operators.py", line 30, in __call__
    return self.function(target, *self.args, **self.kwargs)
P011 yt : [ERROR    ] 2024-04-03 15:28:46,076 TypeError: stellar_mass_recipe() missing 1 required positional argument: 'outputs'
  File "stellar_mass.py", line 92, in <module>
    ap.add_recipe(stellar_mass_recipe)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_pipeline.py", line 140, in add_recipe
    recipe(self)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_operators.py", line 30, in __call__
    return self.function(target, *self.args, **self.kwargs)
P033 yt : [ERROR    ] 2024-04-03 15:28:46,076 TypeError: stellar_mass_recipe() missing 1 required positional argument: 'outputs'
  File "stellar_mass.py", line 92, in <module>
    ap.add_recipe(stellar_mass_recipe)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_pipeline.py", line 140, in add_recipe
    recipe(self)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_operators.py", line 30, in __call__
    return self.function(target, *self.args, **self.kwargs)
P015 yt : [ERROR    ] 2024-04-03 15:28:46,076 TypeError: stellar_mass_recipe() missing 1 required positional argument: 'outputs'
  File "stellar_mass.py", line 92, in <module>
    ap.add_recipe(stellar_mass_recipe)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_pipeline.py", line 140, in add_recipe
    recipe(self)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_operators.py", line 30, in __call__
    return self.function(target, *self.args, **self.kwargs)
P037 yt : [ERROR    ] 2024-04-03 15:28:46,076 TypeError: stellar_mass_recipe() missing 1 required positional argument: 'outputs'
  File "stellar_mass.py", line 92, in <module>
    ap.add_recipe(stellar_mass_recipe)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_pipeline.py", line 140, in add_recipe
    recipe(self)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_operators.py", line 30, in __call__
    return self.function(target, *self.args, **self.kwargs)
P017 yt : [ERROR    ] 2024-04-03 15:28:46,076 TypeError: stellar_mass_recipe() missing 1 required positional argument: 'outputs'
  File "stellar_mass.py", line 92, in <module>
    ap.add_recipe(stellar_mass_recipe)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_pipeline.py", line 140, in add_recipe
    recipe(self)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_operators.py", line 30, in __call__
    return self.function(target, *self.args, **self.kwargs)
P039 yt : [ERROR    ] 2024-04-03 15:28:46,076 TypeError: stellar_mass_recipe() missing 1 required positional argument: 'outputs'
  File "stellar_mass.py", line 92, in <module>
    ap.add_recipe(stellar_mass_recipe)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_pipeline.py", line 140, in add_recipe
    recipe(self)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_operators.py", line 30, in __call__
    return self.function(target, *self.args, **self.kwargs)
P018 yt : [ERROR    ] 2024-04-03 15:28:46,076 TypeError: stellar_mass_recipe() missing 1 required positional argument: 'outputs'
  File "stellar_mass.py", line 92, in <module>
    ap.add_recipe(stellar_mass_recipe)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_pipeline.py", line 140, in add_recipe
    recipe(self)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_operators.py", line 30, in __call__
    return self.function(target, *self.args, **self.kwargs)
P040 yt : [ERROR    ] 2024-04-03 15:28:46,076 TypeError: stellar_mass_recipe() missing 1 required positional argument: 'outputs'
  File "stellar_mass.py", line 92, in <module>
    ap.add_recipe(stellar_mass_recipe)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_pipeline.py", line 140, in add_recipe
    recipe(self)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_operators.py", line 30, in __call__
    return self.function(target, *self.args, **self.kwargs)
P019 yt : [ERROR    ] 2024-04-03 15:28:46,076 TypeError: stellar_mass_recipe() missing 1 required positional argument: 'outputs'
  File "stellar_mass.py", line 92, in <module>
    ap.add_recipe(stellar_mass_recipe)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_pipeline.py", line 140, in add_recipe
    recipe(self)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_operators.py", line 30, in __call__
    return self.function(target, *self.args, **self.kwargs)
P041 yt : [ERROR    ] 2024-04-03 15:28:46,076 TypeError: stellar_mass_recipe() missing 1 required positional argument: 'outputs'
  File "stellar_mass.py", line 92, in <module>
    ap.add_recipe(stellar_mass_recipe)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_pipeline.py", line 140, in add_recipe
    recipe(self)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_operators.py", line 30, in __call__
    return self.function(target, *self.args, **self.kwargs)
P020 yt : [ERROR    ] 2024-04-03 15:28:46,076 TypeError: stellar_mass_recipe() missing 1 required positional argument: 'outputs'
  File "stellar_mass.py", line 92, in <module>
    ap.add_recipe(stellar_mass_recipe)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_pipeline.py", line 140, in add_recipe
    recipe(self)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_operators.py", line 30, in __call__
    return self.function(target, *self.args, **self.kwargs)
P042 yt : [ERROR    ] 2024-04-03 15:28:46,076 TypeError: stellar_mass_recipe() missing 1 required positional argument: 'outputs'
  File "stellar_mass.py", line 92, in <module>
    ap.add_recipe(stellar_mass_recipe)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_pipeline.py", line 140, in add_recipe
    recipe(self)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_operators.py", line 30, in __call__
    return self.function(target, *self.args, **self.kwargs)
P023 yt : [ERROR    ] 2024-04-03 15:28:46,076 TypeError: stellar_mass_recipe() missing 1 required positional argument: 'outputs'
  File "stellar_mass.py", line 92, in <module>
    ap.add_recipe(stellar_mass_recipe)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_pipeline.py", line 140, in add_recipe
    recipe(self)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_operators.py", line 30, in __call__
    return self.function(target, *self.args, **self.kwargs)
P045 yt : [ERROR    ] 2024-04-03 15:28:46,076 TypeError: stellar_mass_recipe() missing 1 required positional argument: 'outputs'
  File "stellar_mass.py", line 92, in <module>
    ap.add_recipe(stellar_mass_recipe)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_pipeline.py", line 140, in add_recipe
    recipe(self)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_operators.py", line 30, in __call__
    return self.function(target, *self.args, **self.kwargs)
P001 yt : [ERROR    ] 2024-04-03 15:28:46,076 TypeError: stellar_mass_recipe() missing 1 required positional argument: 'outputs'
  File "stellar_mass.py", line 92, in <module>
    ap.add_recipe(stellar_mass_recipe)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_pipeline.py", line 140, in add_recipe
    recipe(self)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_operators.py", line 30, in __call__
    return self.function(target, *self.args, **self.kwargs)
P028 yt : [ERROR    ] 2024-04-03 15:28:46,076 TypeError: stellar_mass_recipe() missing 1 required positional argument: 'outputs'
  File "stellar_mass.py", line 92, in <module>
    ap.add_recipe(stellar_mass_recipe)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_pipeline.py", line 140, in add_recipe
    recipe(self)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_operators.py", line 30, in __call__
    return self.function(target, *self.args, **self.kwargs)
P002 yt : [ERROR    ] 2024-04-03 15:28:46,076 TypeError: stellar_mass_recipe() missing 1 required positional argument: 'outputs'
  File "stellar_mass.py", line 92, in <module>
    ap.add_recipe(stellar_mass_recipe)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_pipeline.py", line 140, in add_recipe
    recipe(self)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_operators.py", line 30, in __call__
    return self.function(target, *self.args, **self.kwargs)
P038 yt : [ERROR    ] 2024-04-03 15:28:46,076 TypeError: stellar_mass_recipe() missing 1 required positional argument: 'outputs'
  File "stellar_mass.py", line 92, in <module>
    ap.add_recipe(stellar_mass_recipe)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_pipeline.py", line 140, in add_recipe
    recipe(self)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_operators.py", line 30, in __call__
    return self.function(target, *self.args, **self.kwargs)
P008 yt : [ERROR    ] 2024-04-03 15:28:46,076 TypeError: stellar_mass_recipe() missing 1 required positional argument: 'outputs'
  File "stellar_mass.py", line 92, in <module>
    ap.add_recipe(stellar_mass_recipe)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_pipeline.py", line 140, in add_recipe
    recipe(self)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_operators.py", line 30, in __call__
    return self.function(target, *self.args, **self.kwargs)
P046 yt : [ERROR    ] 2024-04-03 15:28:46,076 TypeError: stellar_mass_recipe() missing 1 required positional argument: 'outputs'
P004 yt : [ERROR    ] 2024-04-03 15:28:46,076 Error occurred on rank 4.
  File "stellar_mass.py", line 92, in <module>
    ap.add_recipe(stellar_mass_recipe)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_pipeline.py", line 140, in add_recipe
    recipe(self)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_operators.py", line 30, in __call__
    return self.function(target, *self.args, **self.kwargs)
P047 yt : [ERROR    ] 2024-04-03 15:28:46,076 TypeError: stellar_mass_recipe() missing 1 required positional argument: 'outputs'
P005 yt : [ERROR    ] 2024-04-03 15:28:46,076 Error occurred on rank 5.
P027 yt : [ERROR    ] 2024-04-03 15:28:46,076 Error occurred on rank 27.
Additional features and improved performance (usually) by saving this arbor with "save_arbor" and reloading:
	>>> a = ytree.load("/storage/home/hcoda1/0/jw254/data/SG64-2020/rockstar_halos-jhw/trees/tree_0_0_0.dat")
	>>> fn = a.save_arbor()
	>>> a = ytree.load(fn)
P016 yt : [ERROR    ] 2024-04-03 15:28:46,076 Error occurred on rank 16.
Additional features and improved performance (usually) by saving this arbor with "save_arbor" and reloading:
	>>> a = ytree.load("/storage/home/hcoda1/0/jw254/data/SG64-2020/rockstar_halos-jhw/trees/tree_0_0_0.dat")
	>>> fn = a.save_arbor()
	>>> a = ytree.load(fn)
P031 yt : [ERROR    ] 2024-04-03 15:28:46,076 Error occurred on rank 31.
P000 yt : [ERROR    ] 2024-04-03 15:28:46,076 Error occurred on rank 0.
P034 yt : [ERROR    ] 2024-04-03 15:28:46,076 Error occurred on rank 34.
P003 yt : [ERROR    ] 2024-04-03 15:28:46,076 Error occurred on rank 3.
P043 yt : [ERROR    ] 2024-04-03 15:28:46,076 Error occurred on rank 43.
P011 yt : [ERROR    ] 2024-04-03 15:28:46,076 Error occurred on rank 11.
P026 yt : [ERROR    ] 2024-04-03 15:28:46,076 Error occurred on rank 26.
P013 yt : [ERROR    ] 2024-04-03 15:28:46,076 Error occurred on rank 13.
P037 yt : [ERROR    ] 2024-04-03 15:28:46,076 Error occurred on rank 37.
P017 yt : [ERROR    ] 2024-04-03 15:28:46,076 Error occurred on rank 17.
P041 yt : [ERROR    ] 2024-04-03 15:28:46,076 Error occurred on rank 41.
P010 yt : [ERROR    ] 2024-04-03 15:28:46,076 Error occurred on rank 10.
P045 yt : [ERROR    ] 2024-04-03 15:28:46,076 Error occurred on rank 45.
P019 yt : [ERROR    ] 2024-04-03 15:28:46,076 Error occurred on rank 19.
P024 yt : [ERROR    ] 2024-04-03 15:28:46,076 Error occurred on rank 24.
P009 yt : [ERROR    ] 2024-04-03 15:28:46,077 Error occurred on rank 9.
P029 yt : [ERROR    ] 2024-04-03 15:28:46,076 Error occurred on rank 29.
P018 yt : [ERROR    ] 2024-04-03 15:28:46,077 Error occurred on rank 18.
P032 yt : [ERROR    ] 2024-04-03 15:28:46,076 Error occurred on rank 32.
P020 yt : [ERROR    ] 2024-04-03 15:28:46,077 Error occurred on rank 20.
P033 yt : [ERROR    ] 2024-04-03 15:28:46,076 Error occurred on rank 33.
P023 yt : [ERROR    ] 2024-04-03 15:28:46,077 Error occurred on rank 23.
P039 yt : [ERROR    ] 2024-04-03 15:28:46,076 Error occurred on rank 39.
P001 yt : [ERROR    ] 2024-04-03 15:28:46,077 Error occurred on rank 1.
P040 yt : [ERROR    ] 2024-04-03 15:28:46,076 Error occurred on rank 40.
P002 yt : [ERROR    ] 2024-04-03 15:28:46,077 Error occurred on rank 2.
P042 yt : [ERROR    ] 2024-04-03 15:28:46,076 Error occurred on rank 42.
P008 yt : [ERROR    ] 2024-04-03 15:28:46,077 Error occurred on rank 8.
P046 yt : [ERROR    ] 2024-04-03 15:28:46,076 Error occurred on rank 46.
P015 yt : [ERROR    ] 2024-04-03 15:28:46,077 Error occurred on rank 15.
P006 yt : [ERROR    ] 2024-04-03 15:28:46,077 Error occurred on rank 6.
P047 yt : [ERROR    ] 2024-04-03 15:28:46,076 Error occurred on rank 47.
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 5 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
P028 yt : [ERROR    ] 2024-04-03 15:28:46,076 Error occurred on rank 28.
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 16 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
P038 yt : [ERROR    ] 2024-04-03 15:28:46,076 Error occurred on rank 38.
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 17 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
  File "stellar_mass.py", line 92, in <module>
    ap.add_recipe(stellar_mass_recipe)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_pipeline.py", line 140, in add_recipe
    recipe(self)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_operators.py", line 30, in __call__
    return self.function(target, *self.args, **self.kwargs)
P035 yt : [ERROR    ] 2024-04-03 15:28:46,078 TypeError: stellar_mass_recipe() missing 1 required positional argument: 'outputs'
P035 yt : [ERROR    ] 2024-04-03 15:28:46,078 Error occurred on rank 35.
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 13 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 3 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
Additional features and improved performance (usually) by saving this arbor with "save_arbor" and reloading:
	>>> a = ytree.load("/storage/home/hcoda1/0/jw254/data/SG64-2020/rockstar_halos-jhw/trees/tree_0_0_0.dat")
	>>> fn = a.save_arbor()
	>>> a = ytree.load(fn)
Additional features and improved performance (usually) by saving this arbor with "save_arbor" and reloading:
	>>> a = ytree.load("/storage/home/hcoda1/0/jw254/data/SG64-2020/rockstar_halos-jhw/trees/tree_0_0_0.dat")
	>>> fn = a.save_arbor()
	>>> a = ytree.load(fn)
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 4 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 43 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 27 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 31 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 11 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
  File "stellar_mass.py", line 92, in <module>
    ap.add_recipe(stellar_mass_recipe)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_pipeline.py", line 140, in add_recipe
    recipe(self)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_operators.py", line 30, in __call__
    return self.function(target, *self.args, **self.kwargs)
P012 yt : [ERROR    ] 2024-04-03 15:28:46,080 TypeError: stellar_mass_recipe() missing 1 required positional argument: 'outputs'
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 45 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
Additional features and improved performance (usually) by saving this arbor with "save_arbor" and reloading:
	>>> a = ytree.load("/storage/home/hcoda1/0/jw254/data/SG64-2020/rockstar_halos-jhw/trees/tree_0_0_0.dat")
	>>> fn = a.save_arbor()
	>>> a = ytree.load(fn)
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 0 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
  File "stellar_mass.py", line 92, in <module>
    ap.add_recipe(stellar_mass_recipe)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_pipeline.py", line 140, in add_recipe
    recipe(self)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_operators.py", line 30, in __call__
    return self.function(target, *self.args, **self.kwargs)
P021 yt : [ERROR    ] 2024-04-03 15:28:46,080 TypeError: stellar_mass_recipe() missing 1 required positional argument: 'outputs'
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 34 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
  File "stellar_mass.py", line 92, in <module>
    ap.add_recipe(stellar_mass_recipe)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_pipeline.py", line 140, in add_recipe
    recipe(self)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_operators.py", line 30, in __call__
    return self.function(target, *self.args, **self.kwargs)
P022 yt : [ERROR    ] 2024-04-03 15:28:46,081 TypeError: stellar_mass_recipe() missing 1 required positional argument: 'outputs'
P012 yt : [ERROR    ] 2024-04-03 15:28:46,080 Error occurred on rank 12.
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 10 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 19 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
P021 yt : [ERROR    ] 2024-04-03 15:28:46,081 Error occurred on rank 21.
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 29 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 12 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
P022 yt : [ERROR    ] 2024-04-03 15:28:46,081 Error occurred on rank 22.
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 26 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 18 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 21 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 22 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 41 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 23 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 32 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 9 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
  File "stellar_mass.py", line 92, in <module>
    ap.add_recipe(stellar_mass_recipe)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_pipeline.py", line 140, in add_recipe
    recipe(self)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_operators.py", line 30, in __call__
    return self.function(target, *self.args, **self.kwargs)
P030 yt : [ERROR    ] 2024-04-03 15:28:46,081 TypeError: stellar_mass_recipe() missing 1 required positional argument: 'outputs'
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 33 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 15 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
  File "stellar_mass.py", line 92, in <module>
    ap.add_recipe(stellar_mass_recipe)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_pipeline.py", line 140, in add_recipe
    recipe(self)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_operators.py", line 30, in __call__
    return self.function(target, *self.args, **self.kwargs)
P044 yt : [ERROR    ] 2024-04-03 15:28:46,081 TypeError: stellar_mass_recipe() missing 1 required positional argument: 'outputs'
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 24 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 2 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
P030 yt : [ERROR    ] 2024-04-03 15:28:46,081 Error occurred on rank 30.
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 39 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
P044 yt : [ERROR    ] 2024-04-03 15:28:46,081 Error occurred on rank 44.
  File "stellar_mass.py", line 92, in <module>
    ap.add_recipe(stellar_mass_recipe)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_pipeline.py", line 140, in add_recipe
    recipe(self)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_operators.py", line 30, in __call__
    return self.function(target, *self.args, **self.kwargs)
P036 yt : [ERROR    ] 2024-04-03 15:28:46,081 TypeError: stellar_mass_recipe() missing 1 required positional argument: 'outputs'
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 20 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 30 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 42 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 44 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
Additional features and improved performance (usually) by saving this arbor with "save_arbor" and reloading:
	>>> a = ytree.load("/storage/home/hcoda1/0/jw254/data/SG64-2020/rockstar_halos-jhw/trees/tree_0_0_0.dat")
	>>> fn = a.save_arbor()
	>>> a = ytree.load(fn)
P036 yt : [ERROR    ] 2024-04-03 15:28:46,081 Error occurred on rank 36.
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 47 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 40 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 36 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 37 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 28 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 38 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 8 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 46 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 1 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
Additional features and improved performance (usually) by saving this arbor with "save_arbor" and reloading:
	>>> a = ytree.load("/storage/home/hcoda1/0/jw254/data/SG64-2020/rockstar_halos-jhw/trees/tree_0_0_0.dat")
	>>> fn = a.save_arbor()
	>>> a = ytree.load(fn)
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 35 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 6 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
Additional features and improved performance (usually) by saving this arbor with "save_arbor" and reloading:
	>>> a = ytree.load("/storage/home/hcoda1/0/jw254/data/SG64-2020/rockstar_halos-jhw/trees/tree_0_0_0.dat")
	>>> fn = a.save_arbor()
	>>> a = ytree.load(fn)
  File "stellar_mass.py", line 92, in <module>
    ap.add_recipe(stellar_mass_recipe)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_pipeline.py", line 140, in add_recipe
    recipe(self)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_operators.py", line 30, in __call__
    return self.function(target, *self.args, **self.kwargs)
P025 yt : [ERROR    ] 2024-04-03 15:28:46,083 TypeError: stellar_mass_recipe() missing 1 required positional argument: 'outputs'
P025 yt : [ERROR    ] 2024-04-03 15:28:46,083 Error occurred on rank 25.
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 25 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
  File "stellar_mass.py", line 92, in <module>
    ap.add_recipe(stellar_mass_recipe)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_pipeline.py", line 140, in add_recipe
    recipe(self)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_operators.py", line 30, in __call__
    return self.function(target, *self.args, **self.kwargs)
P014 yt : [ERROR    ] 2024-04-03 15:28:46,084 TypeError: stellar_mass_recipe() missing 1 required positional argument: 'outputs'
  File "stellar_mass.py", line 92, in <module>
    ap.add_recipe(stellar_mass_recipe)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_pipeline.py", line 140, in add_recipe
    recipe(self)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_operators.py", line 30, in __call__
    return self.function(target, *self.args, **self.kwargs)
P007 yt : [ERROR    ] 2024-04-03 15:28:46,085 TypeError: stellar_mass_recipe() missing 1 required positional argument: 'outputs'
P014 yt : [ERROR    ] 2024-04-03 15:28:46,085 Error occurred on rank 14.
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 14 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
P007 yt : [ERROR    ] 2024-04-03 15:28:46,085 Error occurred on rank 7.
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 7 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
slurmstepd: error: *** STEP 5519235.0 ON atl1-1-02-017-31-2 CANCELLED AT 2024-04-03T15:28:46 ***
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
srun: error: atl1-1-02-017-31-2: tasks 0-23: Killed
srun: error: atl1-1-02-017-35-1: tasks 24-47: Killed
---------------------------------------
Begin Slurm Epilog: Apr-03-2024 15:28:46
Job ID:        5519235
Array Job ID:  _4294967294
User ID:       shardin31
Account:       gts-jw254-coda20
Job name:      Slurmshardinpowderdayrun
Resources:     cpu=48,mem=100G,node=2
Rsrc Used:     cput=00:20:48,vmem=764K,walltime=00:00:26,mem=0,energy_used=0
Partition:     cpu-small
QOS:           inferno
Nodes:         atl1-1-02-017-31-2,atl1-1-02-017-35-1
---------------------------------------

---------------------------------------
Begin Slurm Prolog: Mar-25-2024 12:10:06
Job ID:    5312568
User ID:   shardin31
Account:   gts-jw254-coda20
Job name:  Slurmshardinpowderdayrun
Partition: cpu-small
QOS:       inferno
---------------------------------------

CommandNotFoundError: Your shell has not been properly configured to use 'conda deactivate'.
To initialize your shell, run

    $ conda init <SHELL_NAME>

Currently supported shells are:
  - bash
  - fish
  - tcsh
  - xonsh
  - zsh
  - powershell

See 'conda init --help' for more information and options.

IMPORTANT: You may need to close and restart your shell after running 'conda init'.



Lmod is automatically replacing "mvapich2/2.3.6-ouywal" with "openmpi/4.1.4".

yt : [INFO     ] 2024-03-25 12:10:25,315 Global parallel computation enabled: 3 / 16
yt : [INFO     ] 2024-03-25 12:10:25,321 Global parallel computation enabled: 12 / 16
yt : [INFO     ] 2024-03-25 12:10:25,315 Global parallel computation enabled: 5 / 16
yt : [INFO     ] 2024-03-25 12:10:25,315 Global parallel computation enabled: 0 / 16
yt : [INFO     ] 2024-03-25 12:10:25,315 Global parallel computation enabled: 2 / 16
yt : [INFO     ] 2024-03-25 12:10:25,315 Global parallel computation enabled: 7 / 16
yt : [INFO     ] 2024-03-25 12:10:25,315 Global parallel computation enabled: 4 / 16
yt : [INFO     ] 2024-03-25 12:10:25,315 Global parallel computation enabled: 1 / 16
yt : [INFO     ] 2024-03-25 12:10:25,315 Global parallel computation enabled: 6 / 16
yt : [INFO     ] 2024-03-25 12:10:25,321 Global parallel computation enabled: 13 / 16
yt : [INFO     ] 2024-03-25 12:10:25,322 Global parallel computation enabled: 14 / 16
yt : [INFO     ] 2024-03-25 12:10:25,321 Global parallel computation enabled: 15 / 16
yt : [INFO     ] 2024-03-25 12:10:25,322 Global parallel computation enabled: 8 / 16
yt : [INFO     ] 2024-03-25 12:10:25,322 Global parallel computation enabled: 9 / 16
yt : [INFO     ] 2024-03-25 12:10:25,322 Global parallel computation enabled: 10 / 16
yt : [INFO     ] 2024-03-25 12:10:25,322 Global parallel computation enabled: 11 / 16
Additional features and improved performance (usually) by saving this arbor with "save_arbor" and reloading:
	>>> a = ytree.load("/storage/home/hcoda1/0/jw254/data/SG64-2020/rockstar_halos-jhw/trees/tree_0_0_0.dat")
	>>> fn = a.save_arbor()
	>>> a = ytree.load(fn)
Additional features and improved performance (usually) by saving this arbor with "save_arbor" and reloading:
	>>> a = ytree.load("/storage/home/hcoda1/0/jw254/data/SG64-2020/rockstar_halos-jhw/trees/tree_0_0_0.dat")
	>>> fn = a.save_arbor()
	>>> a = ytree.load(fn)
Additional features and improved performance (usually) by saving this arbor with "save_arbor" and reloading:
	>>> a = ytree.load("/storage/home/hcoda1/0/jw254/data/SG64-2020/rockstar_halos-jhw/trees/tree_0_0_0.dat")
	>>> fn = a.save_arbor()
	>>> a = ytree.load(fn)
Additional features and improved performance (usually) by saving this arbor with "save_arbor" and reloading:
	>>> a = ytree.load("/storage/home/hcoda1/0/jw254/data/SG64-2020/rockstar_halos-jhw/trees/tree_0_0_0.dat")
	>>> fn = a.save_arbor()
	>>> a = ytree.load(fn)
  File "analysis_pipeline.py", line 137, in <module>
    ap.process_target(node)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_pipeline.py", line 174, in process_target
    rval = action(target)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_operators.py", line 30, in __call__
    return self.function(target, *self.args, **self.kwargs)
P004 yt : [ERROR    ] 2024-03-25 12:10:25,454 TypeError: max_stellar_mass_size() takes 0 positional arguments but 1 was given
  File "analysis_pipeline.py", line 137, in <module>
    ap.process_target(node)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_pipeline.py", line 174, in process_target
    rval = action(target)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_operators.py", line 30, in __call__
    return self.function(target, *self.args, **self.kwargs)
P002 yt : [ERROR    ] 2024-03-25 12:10:25,454 TypeError: max_stellar_mass_size() takes 0 positional arguments but 1 was given
Additional features and improved performance (usually) by saving this arbor with "save_arbor" and reloading:
	>>> a = ytree.load("/storage/home/hcoda1/0/jw254/data/SG64-2020/rockstar_halos-jhw/trees/tree_0_0_0.dat")
	>>> fn = a.save_arbor()
	>>> a = ytree.load(fn)
  File "analysis_pipeline.py", line 137, in <module>
    ap.process_target(node)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_pipeline.py", line 174, in process_target
    rval = action(target)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_operators.py", line 30, in __call__
    return self.function(target, *self.args, **self.kwargs)
P001 yt : [ERROR    ] 2024-03-25 12:10:25,456 TypeError: max_stellar_mass_size() takes 0 positional arguments but 1 was given
Additional features and improved performance (usually) by saving this arbor with "save_arbor" and reloading:
	>>> a = ytree.load("/storage/home/hcoda1/0/jw254/data/SG64-2020/rockstar_halos-jhw/trees/tree_0_0_0.dat")
	>>> fn = a.save_arbor()
	>>> a = ytree.load(fn)
  File "analysis_pipeline.py", line 137, in <module>
    ap.process_target(node)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_pipeline.py", line 174, in process_target
    rval = action(target)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_operators.py", line 30, in __call__
    return self.function(target, *self.args, **self.kwargs)
P003 yt : [ERROR    ] 2024-03-25 12:10:25,457 TypeError: max_stellar_mass_size() takes 0 positional arguments but 1 was given
  File "analysis_pipeline.py", line 137, in <module>
    ap.process_target(node)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_pipeline.py", line 174, in process_target
    rval = action(target)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_operators.py", line 30, in __call__
    return self.function(target, *self.args, **self.kwargs)
P007 yt : [ERROR    ] 2024-03-25 12:10:25,458 TypeError: max_stellar_mass_size() takes 0 positional arguments but 1 was given
Additional features and improved performance (usually) by saving this arbor with "save_arbor" and reloading:
	>>> a = ytree.load("/storage/home/hcoda1/0/jw254/data/SG64-2020/rockstar_halos-jhw/trees/tree_0_0_0.dat")
	>>> fn = a.save_arbor()
	>>> a = ytree.load(fn)
Additional features and improved performance (usually) by saving this arbor with "save_arbor" and reloading:
	>>> a = ytree.load("/storage/home/hcoda1/0/jw254/data/SG64-2020/rockstar_halos-jhw/trees/tree_0_0_0.dat")
	>>> fn = a.save_arbor()
	>>> a = ytree.load(fn)
Additional features and improved performance (usually) by saving this arbor with "save_arbor" and reloading:
	>>> a = ytree.load("/storage/home/hcoda1/0/jw254/data/SG64-2020/rockstar_halos-jhw/trees/tree_0_0_0.dat")
	>>> fn = a.save_arbor()
	>>> a = ytree.load(fn)
Additional features and improved performance (usually) by saving this arbor with "save_arbor" and reloading:
	>>> a = ytree.load("/storage/home/hcoda1/0/jw254/data/SG64-2020/rockstar_halos-jhw/trees/tree_0_0_0.dat")
	>>> fn = a.save_arbor()
	>>> a = ytree.load(fn)
Additional features and improved performance (usually) by saving this arbor with "save_arbor" and reloading:
	>>> a = ytree.load("/storage/home/hcoda1/0/jw254/data/SG64-2020/rockstar_halos-jhw/trees/tree_0_0_0.dat")
	>>> fn = a.save_arbor()
	>>> a = ytree.load(fn)
Additional features and improved performance (usually) by saving this arbor with "save_arbor" and reloading:
	>>> a = ytree.load("/storage/home/hcoda1/0/jw254/data/SG64-2020/rockstar_halos-jhw/trees/tree_0_0_0.dat")
	>>> fn = a.save_arbor()
	>>> a = ytree.load(fn)
Additional features and improved performance (usually) by saving this arbor with "save_arbor" and reloading:
	>>> a = ytree.load("/storage/home/hcoda1/0/jw254/data/SG64-2020/rockstar_halos-jhw/trees/tree_0_0_0.dat")
	>>> fn = a.save_arbor()
	>>> a = ytree.load(fn)
Additional features and improved performance (usually) by saving this arbor with "save_arbor" and reloading:
	>>> a = ytree.load("/storage/home/hcoda1/0/jw254/data/SG64-2020/rockstar_halos-jhw/trees/tree_0_0_0.dat")
	>>> fn = a.save_arbor()
	>>> a = ytree.load(fn)
  File "analysis_pipeline.py", line 137, in <module>
    ap.process_target(node)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_pipeline.py", line 174, in process_target
    rval = action(target)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_operators.py", line 30, in __call__
    return self.function(target, *self.args, **self.kwargs)
P006 yt : [ERROR    ] 2024-03-25 12:10:25,462 TypeError: max_stellar_mass_size() takes 0 positional arguments but 1 was given
  File "analysis_pipeline.py", line 137, in <module>
    ap.process_target(node)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_pipeline.py", line 174, in process_target
    rval = action(target)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_operators.py", line 30, in __call__
    return self.function(target, *self.args, **self.kwargs)
P011 yt : [ERROR    ] 2024-03-25 12:10:25,463 TypeError: max_stellar_mass_size() takes 0 positional arguments but 1 was given
  File "analysis_pipeline.py", line 137, in <module>
    ap.process_target(node)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_pipeline.py", line 174, in process_target
    rval = action(target)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_operators.py", line 30, in __call__
    return self.function(target, *self.args, **self.kwargs)
P012 yt : [ERROR    ] 2024-03-25 12:10:25,463 TypeError: max_stellar_mass_size() takes 0 positional arguments but 1 was given
  File "analysis_pipeline.py", line 137, in <module>
    ap.process_target(node)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_pipeline.py", line 174, in process_target
    rval = action(target)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_operators.py", line 30, in __call__
    return self.function(target, *self.args, **self.kwargs)
P014 yt : [ERROR    ] 2024-03-25 12:10:25,463 TypeError: max_stellar_mass_size() takes 0 positional arguments but 1 was given
  File "analysis_pipeline.py", line 137, in <module>
    ap.process_target(node)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_pipeline.py", line 174, in process_target
    rval = action(target)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_operators.py", line 30, in __call__
    return self.function(target, *self.args, **self.kwargs)
P009 yt : [ERROR    ] 2024-03-25 12:10:25,463 TypeError: max_stellar_mass_size() takes 0 positional arguments but 1 was given
  File "analysis_pipeline.py", line 137, in <module>
    ap.process_target(node)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_pipeline.py", line 174, in process_target
    rval = action(target)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_operators.py", line 30, in __call__
    return self.function(target, *self.args, **self.kwargs)
P010 yt : [ERROR    ] 2024-03-25 12:10:25,463 TypeError: max_stellar_mass_size() takes 0 positional arguments but 1 was given
  File "analysis_pipeline.py", line 137, in <module>
    ap.process_target(node)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_pipeline.py", line 174, in process_target
    rval = action(target)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_operators.py", line 30, in __call__
    return self.function(target, *self.args, **self.kwargs)
P013 yt : [ERROR    ] 2024-03-25 12:10:25,463 TypeError: max_stellar_mass_size() takes 0 positional arguments but 1 was given
  File "analysis_pipeline.py", line 137, in <module>
    ap.process_target(node)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_pipeline.py", line 174, in process_target
    rval = action(target)
  File "/storage/home/hcoda1/7/shardin31/.conda/envs/pd_environment_3/lib/python3.8/site-packages/ytree/analysis/analysis_operators.py", line 30, in __call__
    return self.function(target, *self.args, **self.kwargs)
P015 yt : [ERROR    ] 2024-03-25 12:10:25,464 TypeError: max_stellar_mass_size() takes 0 positional arguments but 1 was given
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 11 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 12 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 14 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 13 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 10 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 9 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
Additional features and improved performance (usually) by saving this arbor with "save_arbor" and reloading:
	>>> a = ytree.load("/storage/home/hcoda1/0/jw254/data/SG64-2020/rockstar_halos-jhw/trees/tree_0_0_0.dat")
	>>> fn = a.save_arbor()
	>>> a = ytree.load(fn)
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 15 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
Additional features and improved performance (usually) by saving this arbor with "save_arbor" and reloading:
	>>> a = ytree.load("/storage/home/hcoda1/0/jw254/data/SG64-2020/rockstar_halos-jhw/trees/tree_0_0_0.dat")
	>>> fn = a.save_arbor()
	>>> a = ytree.load(fn)
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 1 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 2 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 3 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 4 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 7 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 6 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
Loading tree roots:   0%|          | 0/7934216 [00:00<?, ?it/s]Loading tree roots: 100%|██████████| 7934216/7934216 [00:00<00:00, 328057825.79it/s]slurmstepd: error: *** STEP 5312568.0 ON atl1-1-02-020-5-1 CANCELLED AT 2024-03-25T12:10:25 ***
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
srun: error: atl1-1-02-020-5-1: tasks 0-7: Killed
srun: error: atl1-1-02-020-34-2: tasks 8-11,13,15: Killed
srun: error: atl1-1-02-020-34-2: tasks 12,14: Exited with exit code 1
---------------------------------------
Begin Slurm Epilog: Mar-25-2024 12:10:25
Job ID:        5312568
Array Job ID:  _4294967294
User ID:       shardin31
Account:       gts-jw254-coda20
Job name:      Slurmshardinpowderdayrun
Resources:     cpu=32,mem=100G,node=2
Rsrc Used:     cput=00:10:40,vmem=24K,walltime=00:00:20,mem=0,energy_used=0
Partition:     cpu-small
QOS:           inferno
Nodes:         atl1-1-02-020-5-1,atl1-1-02-020-34-2
---------------------------------------
